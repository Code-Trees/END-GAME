{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NrSurWA_XM84"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cmkVW4DFcAA7"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYBIr__hdJvW",
    "outputId": "93b77173-c542-47c3-b84c-74ce207f4b8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb\n"
     ]
    }
   ],
   "source": [
    "!ls /content/imdb_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "5848330f-e52f-49a7-ac18-ab07b0cb8136",
    "_uuid": "dc83c491-711e-4278-b0cc-24896e3e812f",
    "id": "K1cspYuNXM87"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.legacy.datasets import IMDB\n",
    "from torchtext.legacy.data import Field, LabelField, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "j6L6NAg5XM88"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "8YJ1c4vQXM88",
    "outputId": "66a1c580-7fba-41c2-8a8d-ba50f916226b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Torch CUDA Version :10.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Torch Version :1.8.1+cu101'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Python Version :3.7.10 (default, May  3 2021, 02:48:31) \\n[GCC 7.5.0]'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Torch CUDA Version :{torch.version.cuda}'\n",
    "f'Torch Version :{torch.__version__}'\n",
    "f'Python Version :{sys.version}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ixoEQjp8XM89"
   },
   "outputs": [],
   "source": [
    "def gpu_check(seed_val = 1):\n",
    "    print('The Seed is set to {}'.format(seed_val))\n",
    "    if torch.cuda.is_available():\n",
    "        print('Model will Run on CUDA.')\n",
    "        print (\"Type 'watch nvidia-smi' to monitor GPU\\n\")\n",
    "        torch.cuda.manual_seed(seed_val)\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        torch.manual_seed(seed_val)\n",
    "        print ('Running in CPU')\n",
    "        device = 'cpu'\n",
    "    cuda = torch.cuda.is_available()\n",
    "    return cuda,seed_val,device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktIAtn89XM8-",
    "outputId": "2bbf2d60-7f20-4e64-d82d-8f3edb992978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Seed is set to 1234\n",
      "Model will Run on CUDA.\n",
      "Type 'watch nvidia-smi' to monitor GPU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cuda,SEED,device = gpu_check(seed_val=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZBmBSftXM8-",
    "outputId": "90bc2406-399f-4e00-9a2f-263806ba8d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 23 14:47:05 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   53C    P0    43W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "D-09gG16r06x"
   },
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    return s.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "luBHAVVmXM8_"
   },
   "outputs": [],
   "source": [
    "# TEXT = Field(tokenize = 'spacy',tokenizer_language = 'en_core_web_sm', lower = True)\n",
    "TEXT = Field(tokenize = tokenize,tokenizer_language = 'en_core_web_sm', lower = True)\n",
    "LABEL = LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CXdq1nbuXM8_"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = IMDB.splits(TEXT, LABEL,root ='/content/imdb_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eqpHA4YCXM9A"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItAx3-A5XM9A",
    "outputId": "65dd8eeb-5a8d-4a33-efa5-73da6dd15507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 17500\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "# display lenght of test and traing data\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "svozR8VZXM9A",
    "outputId": "2c10a1a6-e243-4d93-9567-568db83b6544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['wow.', 'i', 'went', 'to', 'the', 'video', 'store', 'tonight', 'because', 'i', 'was', 'in', 'the', 'mood', 'for', 'a', 'bad', 'b', 'horror', 'movie', 'and', 'i', 'found', 'this', 'gem.', 'i', 'looked', 'at', 'the', 'cover', 'and', 'i', 'thought', 'it', 'looked', 'like', 'just', 'the', 'movie', 'for', 'my', 'mood.', 'i', 'brought', 'it', 'home', 'and', 'put', 'it', 'on.<br', '/><br', '/>this', 'movie', 'was', 'not', 'the', 'b', 'horror', 'movie', 'that', 'i', 'had', 'in', 'mind.', 'this', 'was', 'much', 'worse.', 'i', 'wanted', 'a', 'bad', 'movie', 'but', 'what', 'i', 'got,', 'i', \"didn't\", 'know', 'that', 'crap', 'like', 'this', 'existed', 'amongst', 'man.', 'this', 'movie', 'seemed', 'like', 'a', '5', 'year', 'old', 'wrote', 'and', 'directed', 'it', 'and', 'that', 'is', 'being', 'nice', 'about', 'it.<br', '/><br', '/>i', 'am', 'an', 'aspiring', 'director', 'and', 'this', 'movie', 'made', 'me', 'so', 'mad', 'that', 'someone', 'out', 'there', 'is', 'actually', 'paying', 'this', 'guy', 'to', 'direct', 'movies.', 'he', 'needs', 'to', 'work', 'at', 'a', 'garbage', 'dump', 'shoveling', 'crap', 'where', 'he', 'belongs.<br', '/><br', '/>if', 'you', 'are', 'thinking', 'about', 'renting', 'this', 'or', 'buying', 'it.', 'i', 'will', 'tell', 'you', 'the', 'same', 'thing', 'that', 'i', 'would', 'tell', 'someone', 'getting', 'ready', 'to', 'commit', 'suicide.', '\"don\\'t', 'do', 'it,', \"it's\", 'not', 'worth', 'it!\"', 'i', 'really', 'have', 'nothing', 'nice', 'to', 'say', 'about', 'this', 'movie.', \"don't\", 'do', 'it!'], 'label': 'neg'}\n"
     ]
    }
   ],
   "source": [
    "# display single example at index 0\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7-ZPPwSyXM9B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "WyL3o2uUXM9B",
    "outputId": "205905ec-def0-44d1-a48d-eb0ceb0aaa23"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"kureishi hasn't exactly been blessed with movies that justify the quality of his writing. recent adapted travesty's like 'intimacy' have ruined great writing. but the mother surpasses all his previous incarnations, eclipsing even my beautiful laundrette. a middle-aged woman overcomes widow-hood by having a very carnal relationship with the boyfriend of her emotionally-weak daughter. the fact that you believe all this is credit to the quality of the acting as it is to the finite gift of the writing. and in daniel craig we have a strutting, brash, gruff anti-hero who denies the audience to ever question why a young stud would contemplate bedding a sagging grandmother. beautifully shot, the film fails only in the weak depiction of the peripheral characters, but as a study of inconceivable lust, it's a winner. \""
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = ''\n",
    "filenumber = 11\n",
    "\n",
    "for i in train_data.examples[filenumber].text:\n",
    "    line += i + ' '\n",
    "line\n",
    "\n",
    "train_data.examples[filenumber].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "q9PE4q54XM9B"
   },
   "outputs": [],
   "source": [
    "# Build vocabulary for source and target from training data\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size=25_000)  # using pretrained word embedding\n",
    "LABEL.build_vocab(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bHVCk9oXM9C",
    "outputId": "5ebf9262-9062-426c-cd44-b68872025128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source vocabulary: 25002\n",
      "Unique tokens in TRG vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(vars(TEXT.vocab))\n",
    "print(f\"Unique tokens in source vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in TRG vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "bogX6jtDXM9C"
   },
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# train and test iteartor\n",
    "train_iterator,valid_iterator ,test_iterator = BucketIterator.splits(\n",
    "      (train_data, valid_data,test_data), \n",
    "      batch_size = BATCH_SIZE, \n",
    "      device = device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3Da-tC_aXM9C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "n1udFd0cXM9D"
   },
   "outputs": [],
   "source": [
    "# Model class\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim,emb_dim, hidden_dim, n_layers, dropout):\n",
    "        # input_dim <--- vocabulary size\n",
    "        # output_dim <--- len ([positive, negative]) == 2 \n",
    "        # emb_dim <--- embedding dimension of embedding matrix\n",
    "\n",
    "        super(Model, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "\n",
    "#         self.fc1 = nn.Linear(hidden_dim, hidden_dim//2)\n",
    "#         self.fc2 = nn.Linear(hidden_dim//2, output_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # shape: [source_len, batch_size]\n",
    "        embedded = self.dropout(self.embedding(src)) # shape: [src_len, batch_size, embed_dim]\n",
    "        output, (hidden, cell) = self.rnn(embedded) \n",
    "        # output shape -> [batch, hidden_dim]\n",
    "        # hiddden shape -> [n_layers, batch, hidden_dim]\n",
    "        # cell shape -> [n_layers, batch, hidden_dim]\n",
    "        output = self.fc1(output[-1])\n",
    "#         output = self.fc2(self.relu(output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJ4gPZzAXM9D",
    "outputId": "ea525e80-8480-4ce8-888d-d6892a4b8ebf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "#initializing variables and hyper parameters\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "DEC_EMB_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.6\n",
    "\n",
    "# initializing our model\n",
    "model = Model(INPUT_DIM, OUTPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "cssKRzERXM9E"
   },
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "k9LTjlYCXM9E"
   },
   "outputs": [],
   "source": [
    "# loop and train our model\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "# defining learnig rate scheduler (optional)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "VPPTpYnFXM9E"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Model training function\n",
    "def train(EPOCH,model, iterator, optimizer=optimizer, criterion=criterion, clip=1,):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "    pbar = tqdm(iterator)\n",
    "    for i, batch in enumerate(pbar):\n",
    "        src = batch.text.to(device)\n",
    "        trg = batch.label.to(device)\n",
    "        trg = trg.long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src)\n",
    "        \n",
    "        total_correct += torch.sum(torch.eq(output.argmax(1), trg))\n",
    "        total_count+=len(trg)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward() \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_description(desc= f'Epoch {EPOCH} Train data Batch No : {i} Loss : {loss.item():.3f} Accuracy : {total_correct/total_count * 100 :.2f}% ' )\n",
    "    \n",
    "    train_accuracy.append(total_correct/total_count)\n",
    "    mean_loss = epoch_loss / len(iterator)\n",
    "    train_loss.append(mean_loss)\n",
    "    \n",
    "    scheduler.step(mean_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "_-bx851mXM9G"
   },
   "outputs": [],
   "source": [
    "def evaluate(EPOCH,model, iterator, criterion,typ_loader):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    pbar  = tqdm(iterator)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i,batch in enumerate(pbar):\n",
    "            src = batch.text.to(device)\n",
    "            trg = batch.label.to(device)\n",
    "            trg = trg.long()\n",
    "            predictions = model(src)\n",
    "            \n",
    "            loss = criterion(predictions, trg)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "            pbar.set_description(desc= f'Epoch {EPOCH} {typ_loader} Batch No : {i} Loss : {loss.item():.3f} Accuracy : {epoch_acc / len(iterator)* 100 :.2f}% ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BQoU37TFXM9G"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds.argmax(1) == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "rUowPx2KXM9H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYJ2RintXM9H",
    "outputId": "6b1fca53-c200-4b39-ebb0-031b405fbd99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train data Batch No : 546 Loss : 0.701 Accuracy : 49.77% : 100%|██████████| 547/547 [00:37<00:00, 14.55it/s]\n",
      "Epoch 0 Valid data Batch No : 234 Loss : 0.692 Accuracy : 50.31% : 100%|██████████| 235/235 [00:02<00:00, 86.82it/s]\n",
      "Epoch 0 Test data Batch No : 781 Loss : 0.678 Accuracy : 37.39% : 100%|██████████| 782/782 [00:09<00:00, 86.53it/s]\n",
      "Epoch 1 Train data Batch No : 546 Loss : 0.705 Accuracy : 49.93% : 100%|██████████| 547/547 [00:37<00:00, 14.44it/s]\n",
      "Epoch 1 Valid data Batch No : 234 Loss : 0.686 Accuracy : 49.99% : 100%|██████████| 235/235 [00:02<00:00, 89.57it/s]\n",
      "Epoch 1 Test data Batch No : 781 Loss : 0.704 Accuracy : 57.17% : 100%|██████████| 782/782 [00:08<00:00, 88.91it/s]\n",
      "Epoch 2 Train data Batch No : 546 Loss : 0.718 Accuracy : 50.41% : 100%|██████████| 547/547 [00:37<00:00, 14.41it/s]\n",
      "Epoch 2 Valid data Batch No : 234 Loss : 0.692 Accuracy : 51.52% : 100%|██████████| 235/235 [00:02<00:00, 89.56it/s]\n",
      "Epoch 2 Test data Batch No : 781 Loss : 0.629 Accuracy : 46.12% : 100%|██████████| 782/782 [00:08<00:00, 89.88it/s]\n",
      "Epoch 3 Train data Batch No : 546 Loss : 0.679 Accuracy : 50.71% : 100%|██████████| 547/547 [00:37<00:00, 14.61it/s]\n",
      "Epoch 3 Valid data Batch No : 234 Loss : 0.685 Accuracy : 50.16% : 100%|██████████| 235/235 [00:02<00:00, 89.85it/s]\n",
      "Epoch 3 Test data Batch No : 781 Loss : 0.741 Accuracy : 57.04% : 100%|██████████| 782/782 [00:08<00:00, 89.43it/s]\n",
      "Epoch 4 Train data Batch No : 546 Loss : 0.719 Accuracy : 50.35% : 100%|██████████| 547/547 [00:37<00:00, 14.60it/s]\n",
      "Epoch 4 Valid data Batch No : 234 Loss : 0.711 Accuracy : 49.58% : 100%|██████████| 235/235 [00:02<00:00, 88.88it/s]\n",
      "Epoch 4 Test data Batch No : 781 Loss : 0.778 Accuracy : 56.24% : 100%|██████████| 782/782 [00:08<00:00, 89.35it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_epoch = 5\n",
    "for epoch in range(total_epoch):\n",
    "    result = train(epoch,model=model, iterator=train_iterator)\n",
    "    evaluate(epoch,model,valid_iterator,criterion,'Valid data')\n",
    "    evaluate(epoch,model,test_iterator,criterion,'Test data')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "xz-HGi6JXM9I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "LCdY46v9XM9I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "GBNt3vw0XM9I"
   },
   "outputs": [],
   "source": [
    "# function to experiment movie review sentences\n",
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def predict(sentence):\n",
    "    if type(sentence) == str:\n",
    "        tokanized_sentence = [word.text for word in sp.tokenizer(sentence)]\n",
    "    else:\n",
    "        tokanized_sentence = sentence\n",
    "\n",
    "\n",
    "    input_data = [TEXT.vocab.stoi[word.lower()] for word in tokanized_sentence]\n",
    "    input_data = torch.tensor(input_data, dtype=torch.int64).unsqueeze(1).to(device)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    output = model(input_data)\n",
    "    # print(output)\n",
    "    predict = output.argmax(1)\n",
    "    predict = predict.squeeze(0)\n",
    "    print(output)\n",
    "\n",
    "    if predict>0:\n",
    "        return \"---->> Positive Review\"\n",
    "    else:\n",
    "        return '---->> Negative Review'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WPwgS12DXM9I",
    "outputId": "d0ad1461-9131-4ebf-834b-3d2d2c3116f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9696, -0.5756]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'---->> Negative Review'"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('Very bad') # predict funciton will predict if this is positive or negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "x2uj_PfgXM9I",
    "outputId": "29ab0cc4-b37a-4800-eaee-73cb785129de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0022, 0.0456]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'---->> Positive Review'"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('Very good') # predict funciton will predict if this is positive or negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "stM8TNV9toH1",
    "outputId": "89a4ba6e-d5fe-4411-fb1d-d2ba2324cb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2117, -0.0614]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'---->> Negative Review'"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('i recommend to watch the movie once. It is mindblowing') # predict funciton will predict if this is positive or negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqXAX0yYtwmz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "LSTM-sentiment-analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
