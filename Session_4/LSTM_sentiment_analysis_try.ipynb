{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Important Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NrSurWA_XM84"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "5848330f-e52f-49a7-ac18-ab07b0cb8136",
    "_uuid": "dc83c491-711e-4278-b0cc-24896e3e812f",
    "id": "K1cspYuNXM87"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy.datasets import IMDB\n",
    "from torchtext.legacy.data import Field, LabelField, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j6L6NAg5XM88"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version chcek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "8YJ1c4vQXM88",
    "outputId": "66a1c580-7fba-41c2-8a8d-ba50f916226b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Torch CUDA Version :10.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Torch Version :1.8.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Python Version :3.8.10 (default, May 19 2021, 18:05:58) \\n[GCC 7.3.0]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Torch CUDA Version :{torch.version.cuda}'\n",
    "f'Torch Version :{torch.__version__}'\n",
    "f'Python Version :{sys.version}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Checker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ixoEQjp8XM89"
   },
   "outputs": [],
   "source": [
    "def gpu_check(seed_val = 1):\n",
    "    print('The Seed is set to {}'.format(seed_val))\n",
    "    if torch.cuda.is_available():\n",
    "        print('Model will Run on CUDA.')\n",
    "        print (\"Type 'watch nvidia-smi' to monitor GPU\\n\")\n",
    "        torch.cuda.manual_seed(seed_val)\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        torch.manual_seed(seed_val)\n",
    "        print ('Running in CPU')\n",
    "        device = 'cpu'\n",
    "    cuda = torch.cuda.is_available()\n",
    "    return cuda,seed_val,device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktIAtn89XM8-",
    "outputId": "2bbf2d60-7f20-4e64-d82d-8f3edb992978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Seed is set to 1234\n",
      "Model will Run on CUDA.\n",
      "Type 'watch nvidia-smi' to monitor GPU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cuda,SEED,device = gpu_check(seed_val=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZBmBSftXM8-",
    "outputId": "90bc2406-399f-4e00-9a2f-263806ba8d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 27 17:48:43 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 960M    Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   61C    P0    N/A /  N/A |    454MiB /  4046MiB |     20%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2393      G   /usr/lib/xorg/Xorg                113MiB |\n",
      "|    0   N/A  N/A      2818      G   /usr/bin/gnome-shell               84MiB |\n",
      "|    0   N/A  N/A      4260      G   ...AAAAAAAAA= --shared-files      250MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "D-09gG16r06x"
   },
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    return s.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing spacy for faster execution and loading custion tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "luBHAVVmXM8_"
   },
   "outputs": [],
   "source": [
    "TEXT = Field(tokenize = 'spacy',tokenizer_language = 'en_core_web_sm', lower = True,include_lengths = True)\n",
    "# TEXT = Field(tokenize = tokenize,tokenizer_language = 'en_core_web_sm', lower = True)\n",
    "LABEL = LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the data split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CXdq1nbuXM8_"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = IMDB.splits(TEXT, LABEL,root ='/home/jd/Desktop/DATASET/IMDB_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "eqpHA4YCXM9A"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItAx3-A5XM9A",
    "outputId": "65dd8eeb-5a8d-4a33-efa5-73da6dd15507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 17500\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "# display lenght of test and traing data\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "svozR8VZXM9A",
    "outputId": "2c10a1a6-e243-4d93-9567-568db83b6544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['a', 'terrible', 'movie', 'as', 'everyone', 'has', 'said', '.', 'what', 'made', 'me', 'laugh', 'was', 'the', 'cameo', 'appearance', 'by', 'scott', 'mcnealy', ',', 'giving', 'an', 'award', 'to', 'one', 'of', 'the', 'murdered', 'programmers', 'in', 'front', 'of', 'a', 'wall', 'of', 'sun', 'logos', '.', 'mcnealy', 'is', 'the', 'ceo', 'of', 'sun', 'microsystem', ',', 'a', 'company', 'that', 'practically', 'defines', 'itself', 'by', 'its', 'hatred', 'of', 'microsoft', '.', 'they', 'have', 'been', 'instrumental', 'in', 'filing', 'antitrust', 'complaints', 'against', 'microsoft', '.', 'so', ',', 'were', 'they', 'silly', 'enough', 'to', 'think', 'this', 'bad', 'movie', 'would', 'add', 'fuel', 'to', 'that', 'fire?<br', '/><br', '/>there', \"'s\", 'no', 'public', 'record', 'i', 'see', 'of', 'sun', \"'s\", 'involvement', ',', 'but', 'clearly', 'the', 'makers', 'of', 'this', 'movie', 'know', 'scott', 'mcnealy', '.', 'an', 'interesting', 'mystery', '.'], 'label': 'neg'}\n"
     ]
    }
   ],
   "source": [
    "# display single example at index 0\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-ZPPwSyXM9B"
   },
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "WyL3o2uUXM9B",
    "outputId": "205905ec-def0-44d1-a48d-eb0ceb0aaa23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"wow . one of the greatest movies i have ever - ever seen.<br /><br />absolutely loved it ! before the opening credits were done i was glued to the screen.<br /><br />it 's a sci - fi thriller - and edge of your seat whodunnit . incredible.<br /><br />i wish'd it would never end.<br /><br />lucy liu is a throwaway role . anyone could have played it . the lead actor , jeremy northram was the perfect geeky guy . < br /><br />this movie appeals to me who loved war games , sneakers , and track down.<br /><br />incredible!<br /><br />8 - 22 - 06 . walt d in lv \""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = ''\n",
    "filenumber = 11\n",
    "\n",
    "for i in train_data.examples[filenumber].text:\n",
    "    line += i + ' '\n",
    "line\n",
    "\n",
    "train_data.examples[filenumber].label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build vocabulary for source and target from training data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "q9PE4q54XM9B"
   },
   "outputs": [],
   "source": [
    "# Build vocabulary for source and target from training data\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size=25_000)\n",
    "LABEL.build_vocab(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bHVCk9oXM9C",
    "outputId": "5ebf9262-9062-426c-cd44-b68872025128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source vocabulary: 25002\n",
      "Unique tokens in TRG vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(vars(TEXT.vocab))\n",
    "print(f\"Unique tokens in source vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in TRG vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and test iteartor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bogX6jtDXM9C"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch=True, # necessary for packed_padded_sequence\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_iterator:\n",
    "    text, text_length = batch.text\n",
    "#     logits = model(text, text_length)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([134, 134, 134, 134, 134, 134, 134, 134, 134, 133, 133, 133, 133, 133,\n",
       "        133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133,\n",
       "        133, 133, 132, 132], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([134, 32])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_length\n",
    "text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Da-tC_aXM9C"
   },
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "n1udFd0cXM9D"
   },
   "outputs": [],
   "source": [
    "# Model class\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim,emb_dim, hidden_dim, n_layers, dropout):\n",
    "        # input_dim <--- vocabulary size\n",
    "        # output_dim <--- len ([positive, negative]) == 2 \n",
    "        # emb_dim <--- embedding dimension of embedding matrix\n",
    "\n",
    "        super(Model, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src,Len):\n",
    "        # shape: [source_len, batch_size]\n",
    "        embedded = self.dropout(self.embedding(src)) # shape: [src_len, batch_size, embed_dim]\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, Len.to('cpu'))\n",
    "        output, (hidden, cell) = self.rnn(packed) \n",
    "        # output shape -> [batch, hidden_dim]\n",
    "        # hiddden shape -> [n_layers, batch, hidden_dim]\n",
    "        # cell shape -> [n_layers, batch, hidden_dim]\n",
    "        output = self.fc1(hidden)\n",
    "#         output = self.fc2(self.relu(output))\n",
    "        return output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJ4gPZzAXM9D",
    "outputId": "ea525e80-8480-4ce8-888d-d6892a4b8ebf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jd/anaconda3/envs/eva5/lib/python3.8/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "#initializing variables and hyper parameters\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.6\n",
    "\n",
    "# initializing our model\n",
    "model = Model(INPUT_DIM, OUTPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "cssKRzERXM9E"
   },
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "k9LTjlYCXM9E"
   },
   "outputs": [],
   "source": [
    "# loop and train our model\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "# defining learnig rate scheduler (optional)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "VPPTpYnFXM9E"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(EPOCH,model, iterator, optimizer=optimizer, criterion=criterion, clip=1,):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "    pbar = tqdm(iterator)\n",
    "    for i, batch in enumerate(pbar):\n",
    "        src,data_len = batch.text\n",
    "        src = src.to(device)\n",
    "        trg = batch.label.to(device)\n",
    "        trg = trg.long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src,data_len)\n",
    "        \n",
    "        total_correct += torch.sum(torch.eq(output.argmax(1), trg))\n",
    "        total_count+=len(trg)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward() \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_description(desc= f'Epoch {EPOCH} Train data Batch No : {i} Loss : {loss.item():.3f} Accuracy : {total_correct/total_count * 100 :.2f}% ' )\n",
    "    \n",
    "    train_accuracy.append(total_correct/total_count)\n",
    "    mean_loss = epoch_loss / len(iterator)\n",
    "    train_loss.append(mean_loss)\n",
    "    \n",
    "    scheduler.step(mean_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "_-bx851mXM9G"
   },
   "outputs": [],
   "source": [
    "def evaluate(EPOCH,model, iterator, criterion,typ_loader):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    pbar  = tqdm(iterator)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i,batch in enumerate(pbar):\n",
    "            src,data_len = batch.text\n",
    "            src = src.to(device)\n",
    "            trg = batch.label.to(device)\n",
    "            trg = trg.long()\n",
    "            predictions = model(src,data_len)\n",
    "            \n",
    "            loss = criterion(predictions, trg)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "            pbar.set_description(desc= f'Epoch {EPOCH} {typ_loader} Batch No : {i} Loss : {loss.item():.3f} Accuracy : {epoch_acc / len(iterator)* 100 :.2f}% ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BQoU37TFXM9G"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds.argmax(1) == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUowPx2KXM9H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYJ2RintXM9H",
    "outputId": "6b1fca53-c200-4b39-ebb0-031b405fbd99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train data Batch No : 546 Loss : 0.613 Accuracy : 56.30% : 100%|██████████| 547/547 [00:30<00:00, 18.19it/s]\n",
      "Epoch 0 Valid data Batch No : 234 Loss : 0.604 Accuracy : 66.63% : 100%|██████████| 235/235 [00:05<00:00, 43.10it/s]\n",
      "Epoch 0 Test data Batch No : 781 Loss : 0.556 Accuracy : 66.55% : 100%|██████████| 782/782 [00:17<00:00, 44.03it/s]\n",
      "Epoch 1 Train data Batch No : 546 Loss : 0.490 Accuracy : 70.71% : 100%|██████████| 547/547 [00:30<00:00, 17.93it/s]\n",
      "Epoch 1 Valid data Batch No : 234 Loss : 0.372 Accuracy : 80.70% : 100%|██████████| 235/235 [00:05<00:00, 44.58it/s]\n",
      "Epoch 1 Test data Batch No : 781 Loss : 0.392 Accuracy : 80.68% : 100%|██████████| 782/782 [00:17<00:00, 44.02it/s]\n",
      "Epoch 2 Train data Batch No : 546 Loss : 0.377 Accuracy : 81.60% : 100%|██████████| 547/547 [00:32<00:00, 16.61it/s]\n",
      "Epoch 2 Valid data Batch No : 234 Loss : 0.086 Accuracy : 83.36% : 100%|██████████| 235/235 [00:06<00:00, 38.94it/s]\n",
      "Epoch 2 Test data Batch No : 781 Loss : 0.616 Accuracy : 82.59% : 100%|██████████| 782/782 [00:18<00:00, 42.36it/s]\n",
      "Epoch 3 Train data Batch No : 546 Loss : 0.344 Accuracy : 86.14% : 100%|██████████| 547/547 [00:33<00:00, 16.45it/s]\n",
      "Epoch 3 Valid data Batch No : 234 Loss : 0.052 Accuracy : 84.80% : 100%|██████████| 235/235 [00:05<00:00, 45.43it/s]\n",
      "Epoch 3 Test data Batch No : 781 Loss : 0.470 Accuracy : 84.41% : 100%|██████████| 782/782 [00:16<00:00, 47.73it/s] \n",
      "Epoch 4 Train data Batch No : 546 Loss : 0.383 Accuracy : 88.09% : 100%|██████████| 547/547 [00:29<00:00, 18.50it/s]\n",
      "Epoch 4 Valid data Batch No : 234 Loss : 0.184 Accuracy : 88.09% : 100%|██████████| 235/235 [00:04<00:00, 48.96it/s]\n",
      "Epoch 4 Test data Batch No : 781 Loss : 0.668 Accuracy : 87.74% : 100%|██████████| 782/782 [00:15<00:00, 50.05it/s] \n",
      "Epoch 5 Train data Batch No : 546 Loss : 0.363 Accuracy : 89.69% : 100%|██████████| 547/547 [00:29<00:00, 18.60it/s]\n",
      "Epoch 5 Valid data Batch No : 234 Loss : 0.044 Accuracy : 88.31% : 100%|██████████| 235/235 [00:04<00:00, 49.21it/s]\n",
      "Epoch 5 Test data Batch No : 781 Loss : 0.532 Accuracy : 87.68% : 100%|██████████| 782/782 [00:15<00:00, 49.79it/s] \n",
      "Epoch 6 Train data Batch No : 546 Loss : 0.161 Accuracy : 90.75% : 100%|██████████| 547/547 [00:30<00:00, 18.13it/s]\n",
      "Epoch 6 Valid data Batch No : 234 Loss : 0.014 Accuracy : 88.05% : 100%|██████████| 235/235 [00:04<00:00, 47.17it/s]\n",
      "Epoch 6 Test data Batch No : 781 Loss : 0.667 Accuracy : 87.96% : 100%|██████████| 782/782 [00:15<00:00, 49.04it/s] \n",
      "Epoch 7 Train data Batch No : 546 Loss : 0.244 Accuracy : 91.58% : 100%|██████████| 547/547 [00:29<00:00, 18.84it/s]\n",
      "Epoch 7 Valid data Batch No : 234 Loss : 0.022 Accuracy : 88.44% : 100%|██████████| 235/235 [00:05<00:00, 46.73it/s]\n",
      "Epoch 7 Test data Batch No : 781 Loss : 0.714 Accuracy : 87.41% : 100%|██████████| 782/782 [00:16<00:00, 47.83it/s] \n",
      "Epoch 8 Train data Batch No : 546 Loss : 0.148 Accuracy : 92.67% : 100%|██████████| 547/547 [00:28<00:00, 19.18it/s]\n",
      "Epoch 8 Valid data Batch No : 234 Loss : 0.017 Accuracy : 88.79% : 100%|██████████| 235/235 [00:04<00:00, 53.02it/s]\n",
      "Epoch 8 Test data Batch No : 781 Loss : 0.902 Accuracy : 88.03% : 100%|██████████| 782/782 [00:15<00:00, 50.12it/s] \n",
      "Epoch 9 Train data Batch No : 546 Loss : 0.164 Accuracy : 92.91% : 100%|██████████| 547/547 [00:28<00:00, 19.14it/s]\n",
      "Epoch 9 Valid data Batch No : 234 Loss : 0.011 Accuracy : 89.23% : 100%|██████████| 235/235 [00:04<00:00, 48.63it/s]\n",
      "Epoch 9 Test data Batch No : 781 Loss : 1.465 Accuracy : 87.63% : 100%|██████████| 782/782 [00:16<00:00, 47.81it/s] \n",
      "Epoch 10 Train data Batch No : 546 Loss : 0.159 Accuracy : 93.82% : 100%|██████████| 547/547 [00:30<00:00, 17.74it/s]\n",
      "Epoch 10 Valid data Batch No : 234 Loss : 0.011 Accuracy : 88.83% : 100%|██████████| 235/235 [00:04<00:00, 47.86it/s]\n",
      "Epoch 10 Test data Batch No : 781 Loss : 1.059 Accuracy : 87.17% : 100%|██████████| 782/782 [00:16<00:00, 48.02it/s] \n",
      "Epoch 11 Train data Batch No : 546 Loss : 0.325 Accuracy : 94.16% : 100%|██████████| 547/547 [00:30<00:00, 18.00it/s]\n",
      "Epoch 11 Valid data Batch No : 234 Loss : 0.004 Accuracy : 89.47% : 100%|██████████| 235/235 [00:04<00:00, 49.22it/s]\n",
      "Epoch 11 Test data Batch No : 781 Loss : 1.389 Accuracy : 87.80% : 100%|██████████| 782/782 [00:15<00:00, 50.41it/s] \n",
      "Epoch 12 Train data Batch No : 546 Loss : 0.085 Accuracy : 94.46% : 100%|██████████| 547/547 [00:30<00:00, 17.76it/s]\n",
      "Epoch 12 Valid data Batch No : 234 Loss : 0.006 Accuracy : 89.19% : 100%|██████████| 235/235 [00:05<00:00, 44.65it/s]\n",
      "Epoch 12 Test data Batch No : 781 Loss : 1.342 Accuracy : 87.36% : 100%|██████████| 782/782 [00:17<00:00, 44.98it/s]\n",
      "Epoch 13 Train data Batch No : 546 Loss : 0.114 Accuracy : 94.87% : 100%|██████████| 547/547 [00:31<00:00, 17.32it/s]\n",
      "Epoch 13 Valid data Batch No : 234 Loss : 0.013 Accuracy : 89.52% : 100%|██████████| 235/235 [00:05<00:00, 44.87it/s]\n",
      "Epoch 13 Test data Batch No : 781 Loss : 1.133 Accuracy : 87.47% : 100%|██████████| 782/782 [00:16<00:00, 46.93it/s]\n",
      "Epoch 14 Train data Batch No : 546 Loss : 0.147 Accuracy : 95.17% : 100%|██████████| 547/547 [00:29<00:00, 18.47it/s]\n",
      "Epoch 14 Valid data Batch No : 234 Loss : 0.002 Accuracy : 89.53% : 100%|██████████| 235/235 [00:04<00:00, 51.13it/s]\n",
      "Epoch 14 Test data Batch No : 781 Loss : 1.027 Accuracy : 87.85% : 100%|██████████| 782/782 [00:15<00:00, 50.44it/s] \n",
      "Epoch 15 Train data Batch No : 546 Loss : 0.075 Accuracy : 95.55% : 100%|██████████| 547/547 [00:28<00:00, 18.93it/s]\n",
      "Epoch 15 Valid data Batch No : 234 Loss : 0.039 Accuracy : 89.63% : 100%|██████████| 235/235 [00:04<00:00, 50.56it/s]\n",
      "Epoch 15 Test data Batch No : 781 Loss : 1.581 Accuracy : 87.60% : 100%|██████████| 782/782 [00:14<00:00, 52.35it/s] \n",
      "Epoch 16 Train data Batch No : 546 Loss : 0.058 Accuracy : 95.89% : 100%|██████████| 547/547 [00:28<00:00, 19.05it/s]\n",
      "Epoch 16 Valid data Batch No : 234 Loss : 0.003 Accuracy : 89.04% : 100%|██████████| 235/235 [00:04<00:00, 51.16it/s]\n",
      "Epoch 16 Test data Batch No : 781 Loss : 1.047 Accuracy : 87.48% : 100%|██████████| 782/782 [00:14<00:00, 52.58it/s] \n",
      "Epoch 17 Train data Batch No : 546 Loss : 0.094 Accuracy : 96.15% : 100%|██████████| 547/547 [00:28<00:00, 19.17it/s]\n",
      "Epoch 17 Valid data Batch No : 234 Loss : 0.016 Accuracy : 89.96% : 100%|██████████| 235/235 [00:04<00:00, 51.36it/s]\n",
      "Epoch 17 Test data Batch No : 781 Loss : 1.643 Accuracy : 87.66% : 100%|██████████| 782/782 [00:14<00:00, 52.15it/s] \n",
      "Epoch 18 Train data Batch No : 546 Loss : 0.182 Accuracy : 96.29% : 100%|██████████| 547/547 [00:28<00:00, 18.96it/s]\n",
      "Epoch 18 Valid data Batch No : 234 Loss : 0.003 Accuracy : 89.48% : 100%|██████████| 235/235 [00:04<00:00, 51.44it/s]\n",
      "Epoch 18 Test data Batch No : 781 Loss : 0.746 Accuracy : 87.35% : 100%|██████████| 782/782 [00:14<00:00, 52.43it/s] \n",
      "Epoch 19 Train data Batch No : 546 Loss : 0.029 Accuracy : 96.52% : 100%|██████████| 547/547 [00:28<00:00, 19.24it/s]\n",
      "Epoch 19 Valid data Batch No : 234 Loss : 0.024 Accuracy : 88.92% : 100%|██████████| 235/235 [00:04<00:00, 49.32it/s]\n",
      "Epoch 19 Test data Batch No : 781 Loss : 0.083 Accuracy : 87.21% : 100%|██████████| 782/782 [00:15<00:00, 49.35it/s] \n",
      "Epoch 20 Train data Batch No : 546 Loss : 0.176 Accuracy : 96.79% : 100%|██████████| 547/547 [00:29<00:00, 18.61it/s]\n",
      "Epoch 20 Valid data Batch No : 234 Loss : 0.103 Accuracy : 89.43% : 100%|██████████| 235/235 [00:05<00:00, 44.73it/s]\n",
      "Epoch 20 Test data Batch No : 781 Loss : 2.369 Accuracy : 86.79% : 100%|██████████| 782/782 [00:16<00:00, 48.20it/s]\n",
      "Epoch 21 Train data Batch No : 546 Loss : 0.101 Accuracy : 97.15% : 100%|██████████| 547/547 [00:29<00:00, 18.52it/s]\n",
      "Epoch 21 Valid data Batch No : 234 Loss : 0.002 Accuracy : 89.30% : 100%|██████████| 235/235 [00:04<00:00, 48.54it/s]\n",
      "Epoch 21 Test data Batch No : 781 Loss : 1.570 Accuracy : 86.88% : 100%|██████████| 782/782 [00:15<00:00, 49.25it/s] \n",
      "Epoch 22 Train data Batch No : 546 Loss : 0.027 Accuracy : 97.07% : 100%|██████████| 547/547 [00:28<00:00, 18.89it/s]\n",
      "Epoch 22 Valid data Batch No : 234 Loss : 0.011 Accuracy : 89.34% : 100%|██████████| 235/235 [00:04<00:00, 50.98it/s]\n",
      "Epoch 22 Test data Batch No : 781 Loss : 1.318 Accuracy : 87.14% : 100%|██████████| 782/782 [00:15<00:00, 51.90it/s] \n",
      "Epoch 23 Train data Batch No : 546 Loss : 0.046 Accuracy : 97.29% : 100%|██████████| 547/547 [00:27<00:00, 19.70it/s]\n",
      "Epoch 23 Valid data Batch No : 234 Loss : 0.004 Accuracy : 89.51% : 100%|██████████| 235/235 [00:04<00:00, 53.87it/s]\n",
      "Epoch 23 Test data Batch No : 781 Loss : 1.590 Accuracy : 86.97% : 100%|██████████| 782/782 [00:14<00:00, 53.85it/s] \n",
      "Epoch 24 Train data Batch No : 546 Loss : 0.021 Accuracy : 97.69% : 100%|██████████| 547/547 [00:29<00:00, 18.72it/s]\n",
      "Epoch 24 Valid data Batch No : 234 Loss : 0.001 Accuracy : 89.44% : 100%|██████████| 235/235 [00:04<00:00, 47.16it/s]\n",
      "Epoch 24 Test data Batch No : 781 Loss : 1.570 Accuracy : 86.86% : 100%|██████████| 782/782 [00:15<00:00, 51.00it/s] \n",
      "Epoch 25 Train data Batch No : 546 Loss : 0.031 Accuracy : 97.65% : 100%|██████████| 547/547 [00:29<00:00, 18.79it/s]\n",
      "Epoch 25 Valid data Batch No : 234 Loss : 0.002 Accuracy : 89.80% : 100%|██████████| 235/235 [00:04<00:00, 49.73it/s]\n",
      "Epoch 25 Test data Batch No : 781 Loss : 1.429 Accuracy : 87.18% : 100%|██████████| 782/782 [00:15<00:00, 50.81it/s] \n",
      "Epoch 26 Train data Batch No : 546 Loss : 0.362 Accuracy : 97.71% : 100%|██████████| 547/547 [00:28<00:00, 18.98it/s]\n",
      "Epoch 26 Valid data Batch No : 234 Loss : 0.009 Accuracy : 89.34% : 100%|██████████| 235/235 [00:04<00:00, 49.78it/s]\n",
      "Epoch 26 Test data Batch No : 781 Loss : 1.082 Accuracy : 86.52% : 100%|██████████| 782/782 [00:16<00:00, 48.55it/s] \n",
      "Epoch 27 Train data Batch No : 546 Loss : 0.132 Accuracy : 97.81% : 100%|██████████| 547/547 [00:30<00:00, 17.98it/s]\n",
      "Epoch 27 Valid data Batch No : 234 Loss : 0.001 Accuracy : 89.47% : 100%|██████████| 235/235 [00:04<00:00, 49.56it/s]\n",
      "Epoch 27 Test data Batch No : 781 Loss : 2.040 Accuracy : 86.51% : 100%|██████████| 782/782 [00:15<00:00, 50.81it/s] \n",
      "Epoch 28 Train data Batch No : 546 Loss : 0.013 Accuracy : 97.94% : 100%|██████████| 547/547 [00:29<00:00, 18.49it/s]\n",
      "Epoch 28 Valid data Batch No : 234 Loss : 0.002 Accuracy : 89.64% : 100%|██████████| 235/235 [00:04<00:00, 52.22it/s]\n",
      "Epoch 28 Test data Batch No : 781 Loss : 2.493 Accuracy : 86.75% : 100%|██████████| 782/782 [00:15<00:00, 49.70it/s] \n",
      "Epoch 29 Train data Batch No : 546 Loss : 0.043 Accuracy : 98.02% : 100%|██████████| 547/547 [00:29<00:00, 18.54it/s]\n",
      "Epoch 29 Valid data Batch No : 234 Loss : 0.001 Accuracy : 89.83% : 100%|██████████| 235/235 [00:04<00:00, 47.56it/s]\n",
      "Epoch 29 Test data Batch No : 781 Loss : 0.900 Accuracy : 87.15% : 100%|██████████| 782/782 [00:15<00:00, 49.17it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_epoch = 30\n",
    "for epoch in range(total_epoch):\n",
    "    result = train(epoch,model=model, iterator=train_iterator)\n",
    "    evaluate(epoch,model,valid_iterator,criterion,'Valid data')\n",
    "    evaluate(epoch,model,test_iterator,criterion,'Test data')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xz-HGi6JXM9I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCdY46v9XM9I"
   },
   "source": [
    "### function to experiment movie review sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "GBNt3vw0XM9I"
   },
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def predict(sentence):\n",
    "    if type(sentence) == str:\n",
    "        tokanized_sentence = [word.text for word in sp.tokenizer(sentence)]\n",
    "    else:\n",
    "        tokanized_sentence = sentence\n",
    "\n",
    "\n",
    "    input_data = [TEXT.vocab.stoi[word.lower()] for word in tokanized_sentence]\n",
    "    input_data = torch.tensor(input_data, dtype=torch.int64).unsqueeze(1).to(device)\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    output = model(input_data)\n",
    "    # print(output)\n",
    "    predict = output.argmax(1)\n",
    "    predict = predict.squeeze(0)\n",
    "    print(output)\n",
    "\n",
    "    if predict>0:\n",
    "        return \"---->> Positive Review\"\n",
    "    else:\n",
    "        return '---->> Negative Review'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WPwgS12DXM9I",
    "outputId": "d0ad1461-9131-4ebf-834b-3d2d2c3116f7"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f1f4ca80c98b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Very bad'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# predict funciton will predict if this is positive or negative review.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-c5590c41b6ff>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eva5/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-9d85ef6edc84>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, Len)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# shape: [source_len, batch_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# shape: [src_len, batch_size, embed_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# output shape -> [batch, hidden_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "predict('Very bad') # predict funciton will predict if this is positive or negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "x2uj_PfgXM9I",
    "outputId": "29ab0cc4-b37a-4800-eaee-73cb785129de"
   },
   "outputs": [],
   "source": [
    "predict('Very good') # predict funciton will predict if this is positive or negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "stM8TNV9toH1",
    "outputId": "89a4ba6e-d5fe-4411-fb1d-d2ba2324cb5a"
   },
   "outputs": [],
   "source": [
    "predict('i recommend to watch the movie once. It is mindblowing') # predict funciton will predict if this is positive or negative review."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "LSTM-sentiment-analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
