{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Important Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrSurWA_XM84"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5848330f-e52f-49a7-ac18-ab07b0cb8136",
    "_uuid": "dc83c491-711e-4278-b0cc-24896e3e812f",
    "id": "K1cspYuNXM87"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy.datasets import IMDB\n",
    "from torchtext.legacy.data import Field, LabelField, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6L6NAg5XM88"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version chcek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "8YJ1c4vQXM88",
    "outputId": "66a1c580-7fba-41c2-8a8d-ba50f916226b"
   },
   "outputs": [],
   "source": [
    "f'Torch CUDA Version :{torch.version.cuda}'\n",
    "f'Torch Version :{torch.__version__}'\n",
    "f'Python Version :{sys.version}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Checker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixoEQjp8XM89"
   },
   "outputs": [],
   "source": [
    "def gpu_check(seed_val = 1):\n",
    "    print('The Seed is set to {}'.format(seed_val))\n",
    "    if torch.cuda.is_available():\n",
    "        print('Model will Run on CUDA.')\n",
    "        print (\"Type 'watch nvidia-smi' to monitor GPU\\n\")\n",
    "        torch.cuda.manual_seed(seed_val)\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        torch.manual_seed(seed_val)\n",
    "        print ('Running in CPU')\n",
    "        device = 'cpu'\n",
    "    cuda = torch.cuda.is_available()\n",
    "    return cuda,seed_val,device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktIAtn89XM8-",
    "outputId": "2bbf2d60-7f20-4e64-d82d-8f3edb992978"
   },
   "outputs": [],
   "source": [
    "cuda,SEED,device = gpu_check(seed_val=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZBmBSftXM8-",
    "outputId": "90bc2406-399f-4e00-9a2f-263806ba8d82"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-09gG16r06x"
   },
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    return s.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing spacy for faster execution and loading custion tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luBHAVVmXM8_"
   },
   "outputs": [],
   "source": [
    "TEXT = Field(tokenize = 'spacy',tokenizer_language = 'en_core_web_sm', lower = True,include_lengths = True)\n",
    "# TEXT = Field(tokenize = tokenize,tokenizer_language = 'en_core_web_sm', lower = True)\n",
    "LABEL = LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the data split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXdq1nbuXM8_"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = IMDB.splits(TEXT, LABEL,root ='/home/jd/Desktop/DATASET/IMDB_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqpHA4YCXM9A"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItAx3-A5XM9A",
    "outputId": "65dd8eeb-5a8d-4a33-efa5-73da6dd15507"
   },
   "outputs": [],
   "source": [
    "# display lenght of test and traing data\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "svozR8VZXM9A",
    "outputId": "2c10a1a6-e243-4d93-9567-568db83b6544"
   },
   "outputs": [],
   "source": [
    "# display single example at index 0\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-ZPPwSyXM9B"
   },
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "WyL3o2uUXM9B",
    "outputId": "205905ec-def0-44d1-a48d-eb0ceb0aaa23"
   },
   "outputs": [],
   "source": [
    "line = ''\n",
    "filenumber = 11\n",
    "\n",
    "for i in train_data.examples[filenumber].text:\n",
    "    line += i + ' '\n",
    "line\n",
    "\n",
    "train_data.examples[filenumber].label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build vocabulary for source and target from training data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9PE4q54XM9B"
   },
   "outputs": [],
   "source": [
    "# Build vocabulary for source and target from training data\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size=25_000)\n",
    "LABEL.build_vocab(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bHVCk9oXM9C",
    "outputId": "5ebf9262-9062-426c-cd44-b68872025128"
   },
   "outputs": [],
   "source": [
    "\n",
    "# print(vars(TEXT.vocab))\n",
    "print(f\"Unique tokens in source vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in TRG vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and test iteartor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bogX6jtDXM9C"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch=True, # necessary for packed_padded_sequence\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_iterator:\n",
    "    text, text_length = batch.text\n",
    "#     logits = model(text, text_length)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length\n",
    "text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Da-tC_aXM9C"
   },
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n1udFd0cXM9D"
   },
   "outputs": [],
   "source": [
    "# Model class\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim,emb_dim, hidden_dim, n_layers, dropout):\n",
    "        # input_dim <--- vocabulary size\n",
    "        # output_dim <--- len ([positive, negative]) == 2 \n",
    "        # emb_dim <--- embedding dimension of embedding matrix\n",
    "\n",
    "        super(Model, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src,Len):\n",
    "        # shape: [source_len, batch_size]\n",
    "        embedded = self.dropout(self.embedding(src)) # shape: [src_len, batch_size, embed_dim]\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, Len.to('cpu'))\n",
    "        output, (hidden, cell) = self.rnn(packed) \n",
    "        # output shape -> [batch, hidden_dim]\n",
    "        # hiddden shape -> [n_layers, batch, hidden_dim]\n",
    "        # cell shape -> [n_layers, batch, hidden_dim]\n",
    "        output = self.fc1(hidden)\n",
    "#         output = self.fc2(self.relu(output))\n",
    "        return output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJ4gPZzAXM9D",
    "outputId": "ea525e80-8480-4ce8-888d-d6892a4b8ebf"
   },
   "outputs": [],
   "source": [
    "#initializing variables and hyper parameters\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.6\n",
    "\n",
    "# initializing our model\n",
    "model = Model(INPUT_DIM, OUTPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cssKRzERXM9E"
   },
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9LTjlYCXM9E"
   },
   "outputs": [],
   "source": [
    "# loop and train our model\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "# defining learnig rate scheduler (optional)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPPTpYnFXM9E"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(EPOCH,model, iterator, optimizer=optimizer, criterion=criterion, clip=1,):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "    pbar = tqdm(iterator)\n",
    "    for i, batch in enumerate(pbar):\n",
    "        src,data_len = batch.text\n",
    "        src = src.to(device)\n",
    "        trg = batch.label.to(device)\n",
    "        trg = trg.long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src,data_len)\n",
    "        \n",
    "        total_correct += torch.sum(torch.eq(output.argmax(1), trg))\n",
    "        total_count+=len(trg)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward() \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_description(desc= f'Epoch {EPOCH} Train data Batch No : {i} Loss : {loss.item():.3f} Accuracy : {total_correct/total_count * 100 :.2f}% ' )\n",
    "    \n",
    "    train_accuracy.append(total_correct/total_count)\n",
    "    mean_loss = epoch_loss / len(iterator)\n",
    "    train_loss.append(mean_loss)\n",
    "    \n",
    "    scheduler.step(mean_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-bx851mXM9G"
   },
   "outputs": [],
   "source": [
    "def evaluate(EPOCH,model, iterator, criterion,typ_loader):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    pbar  = tqdm(iterator)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i,batch in enumerate(pbar):\n",
    "            src,data_len = batch.text\n",
    "            src = src.to(device)\n",
    "            trg = batch.label.to(device)\n",
    "            trg = trg.long()\n",
    "            predictions = model(src,data_len)\n",
    "            \n",
    "            loss = criterion(predictions, trg)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "            pbar.set_description(desc= f'Epoch {EPOCH} {typ_loader} Batch No : {i} Loss : {loss.item():.3f} Accuracy : {epoch_acc / len(iterator)* 100 :.2f}% ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQoU37TFXM9G"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds.argmax(1) == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUowPx2KXM9H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYJ2RintXM9H",
    "outputId": "6b1fca53-c200-4b39-ebb0-031b405fbd99"
   },
   "outputs": [],
   "source": [
    "\n",
    "total_epoch = 30\n",
    "for epoch in range(total_epoch):\n",
    "    result = train(epoch,model=model, iterator=train_iterator)\n",
    "    evaluate(epoch,model,valid_iterator,criterion,'Valid data')\n",
    "    evaluate(epoch,model,test_iterator,criterion,'Test data')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xz-HGi6JXM9I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCdY46v9XM9I"
   },
   "source": [
    "### function to experiment movie review sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBNt3vw0XM9I"
   },
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def predict(sentence):\n",
    "    if type(sentence) == str:\n",
    "        tokanized_sentence = [word.text for word in sp.tokenizer(sentence)]\n",
    "    else:\n",
    "        tokanized_sentence = sentence\n",
    "\n",
    "\n",
    "    input_data = [TEXT.vocab.stoi[word.lower()] for word in tokanized_sentence]\n",
    "    input_data = torch.tensor(input_data, dtype=torch.int64).unsqueeze(1).to(device)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    output = model(input_data)\n",
    "    # print(output)\n",
    "    predict = output.argmax(1)\n",
    "    predict = predict.squeeze(0)\n",
    "    print(output)\n",
    "\n",
    "    if predict>0:\n",
    "        return \"---->> Positive Review\"\n",
    "    else:\n",
    "        return '---->> Negative Review'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WPwgS12DXM9I",
    "outputId": "d0ad1461-9131-4ebf-834b-3d2d2c3116f7"
   },
   "outputs": [],
   "source": [
    "predict('Very bad') # predict funciton will predict if this is positive or negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "x2uj_PfgXM9I",
    "outputId": "29ab0cc4-b37a-4800-eaee-73cb785129de"
   },
   "outputs": [],
   "source": [
    "predict('Very good') # predict funciton will predict if this is positive or negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "stM8TNV9toH1",
    "outputId": "89a4ba6e-d5fe-4411-fb1d-d2ba2324cb5a"
   },
   "outputs": [],
   "source": [
    "predict('i recommend to watch the movie once. It is mindblowing') # predict funciton will predict if this is positive or negative review."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "LSTM-sentiment-analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
