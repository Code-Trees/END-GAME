{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3AIljihtKB5"
   },
   "source": [
    "### Importing Important Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NrSurWA_XM84"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "5848330f-e52f-49a7-ac18-ab07b0cb8136",
    "_uuid": "dc83c491-711e-4278-b0cc-24896e3e812f",
    "id": "K1cspYuNXM87"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy.datasets import IMDB\n",
    "from torchtext.legacy.data import Field, LabelField, BucketIterator,Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j6L6NAg5XM88"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch, torchtext\n",
    "import os\n",
    "import googletrans\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOhuk1CWtKB-"
   },
   "source": [
    "### Version chcek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "8YJ1c4vQXM88",
    "outputId": "65cb0501-2956-498c-bb8a-59cdbd263a5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Torch CUDA Version :10.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Torch Version :1.8.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Python Version :3.8.10 (default, May 19 2021, 18:05:58) \\n[GCC 7.3.0]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Torch CUDA Version :{torch.version.cuda}'\n",
    "f'Torch Version :{torch.__version__}'\n",
    "f'Python Version :{sys.version}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHAxLOfntKB_"
   },
   "source": [
    "### GPU Checker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ixoEQjp8XM89"
   },
   "outputs": [],
   "source": [
    "def gpu_check(seed_val = 1):\n",
    "    print('The Seed is set to {}'.format(seed_val))\n",
    "    if torch.cuda.is_available():\n",
    "        print('Model will Run on CUDA.')\n",
    "        print (\"Type 'watch nvidia-smi' to monitor GPU\\n\")\n",
    "        torch.cuda.manual_seed(seed_val)\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        torch.manual_seed(seed_val)\n",
    "        print ('Running in CPU')\n",
    "        device = 'cpu'\n",
    "    cuda = torch.cuda.is_available()\n",
    "    return cuda,seed_val,device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktIAtn89XM8-",
    "outputId": "5ae4969d-97e3-4adf-d393-cd39f570ac3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Seed is set to 1234\n",
      "Running in CPU\n"
     ]
    }
   ],
   "source": [
    "cuda,SEED,device = gpu_check(seed_val=1234)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZBmBSftXM8-",
    "outputId": "16cf6738-f23e-437b-ca6c-5abdf6130e0b"
   },
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_dataset(sst_dir):\n",
    "    sentiment_labels = pd.read_csv(os.path.join(sst_dir, \"sentiment_labels.txt\"), sep=\"|\")\n",
    "    sentence_ids = pd.read_csv(os.path.join(sst_dir, \"datasetSentences.txt\"), sep=\"\\t\")\n",
    "    dictionary = pd.read_csv(os.path.join(sst_dir, \"dictionary.txt\"), sep=\"|\", names=['phrase', 'phrase ids'])\n",
    "    train_test_split = pd.read_csv(os.path.join(sst_dir, \"datasetSplit.txt\"))\n",
    "    sentence_phrase_merge = pd.merge(sentence_ids, dictionary, left_on='sentence', right_on='phrase')\n",
    "    sentence_phrase_split = pd.merge(sentence_phrase_merge, train_test_split, on='sentence_index')\n",
    "    return pd.merge(sentence_phrase_split, sentiment_labels, on='phrase ids').sample(frac=1)\n",
    "\n",
    "def discretize_label(label):\n",
    "    if label <= 0.2: return 'Class1'\n",
    "    if label <= 0.4: return 'Class2'\n",
    "    if label <= 0.6: return 'Class3'\n",
    "    if label <= 0.8: return 'Class4'\n",
    "    return 'Class5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_dir = 'stanfordSentimentTreebank/'\n",
    "df = get_merged_dataset(sst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>phrase</th>\n",
       "      <th>phrase ids</th>\n",
       "      <th>splitset_label</th>\n",
       "      <th>sentiment values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10811</th>\n",
       "      <td>11355</td>\n",
       "      <td>And that should tell you everything you need t...</td>\n",
       "      <td>And that should tell you everything you need t...</td>\n",
       "      <td>222377</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3371</th>\n",
       "      <td>3529</td>\n",
       "      <td>` Moore is like a progressive bull in a china ...</td>\n",
       "      <td>` Moore is like a progressive bull in a china ...</td>\n",
       "      <td>71201</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11237</th>\n",
       "      <td>11801</td>\n",
       "      <td>Grating and tedious .</td>\n",
       "      <td>Grating and tedious .</td>\n",
       "      <td>223531</td>\n",
       "      <td>1</td>\n",
       "      <td>0.361110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10247</th>\n",
       "      <td>10750</td>\n",
       "      <td>Dismally dull sci-fi comedy .</td>\n",
       "      <td>Dismally dull sci-fi comedy .</td>\n",
       "      <td>183481</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8390</th>\n",
       "      <td>8785</td>\n",
       "      <td>While Super Troopers is above Academy standard...</td>\n",
       "      <td>While Super Troopers is above Academy standard...</td>\n",
       "      <td>150910</td>\n",
       "      <td>2</td>\n",
       "      <td>0.263890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_index                                           sentence  \\\n",
       "10811           11355  And that should tell you everything you need t...   \n",
       "3371             3529  ` Moore is like a progressive bull in a china ...   \n",
       "11237           11801                              Grating and tedious .   \n",
       "10247           10750                      Dismally dull sci-fi comedy .   \n",
       "8390             8785  While Super Troopers is above Academy standard...   \n",
       "\n",
       "                                                  phrase  phrase ids  \\\n",
       "10811  And that should tell you everything you need t...      222377   \n",
       "3371   ` Moore is like a progressive bull in a china ...       71201   \n",
       "11237                              Grating and tedious .      223531   \n",
       "10247                      Dismally dull sci-fi comedy .      183481   \n",
       "8390   While Super Troopers is above Academy standard...      150910   \n",
       "\n",
       "       splitset_label  sentiment values  \n",
       "10811               1          0.416670  \n",
       "3371                1          0.347220  \n",
       "11237               1          0.361110  \n",
       "10247               1          0.083333  \n",
       "8390                2          0.263890  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['sentiment values'].apply(discretize_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11286, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Class2    2971\n",
       "Class4    2966\n",
       "Class3    2144\n",
       "Class5    1773\n",
       "Class1    1432\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df[['sentence','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(df,train_size=.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11286, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df2.to_csv('augmented_data.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df2 = pd.read_csv('augmented_data.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.concat([df,df2]).reset_index(drop =True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dense and enigmatic ... elusive ... stagy and stilted'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Class3'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentence[2733]\n",
    "df.label[2733]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>And that should tell you everything you need t...</td>\n",
       "      <td>Class3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>` Moore is like a progressive bull in a china ...</td>\n",
       "      <td>Class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grating and tedious .</td>\n",
       "      <td>Class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dismally dull sci-fi comedy .</td>\n",
       "      <td>Class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>While Super Troopers is above Academy standard...</td>\n",
       "      <td>Class2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence   label\n",
       "0  And that should tell you everything you need t...  Class3\n",
       "1  ` Moore is like a progressive bull in a china ...  Class2\n",
       "2                              Grating and tedious .  Class2\n",
       "3                      Dismally dull sci-fi comedy .  Class1\n",
       "4  While Super Troopers is above Academy standard...  Class2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>And that should tell you everything you need t...</td>\n",
       "      <td>Class3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>` Moore is like a progressive bull in a china ...</td>\n",
       "      <td>Class2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence   label\n",
       "0  And that should tell you everything you need t...  Class3\n",
       "1  ` Moore is like a progressive bull in a china ...  Class2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jd/anaconda3/envs/eva/lib/python3.8/site-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
     ]
    }
   ],
   "source": [
    "TEXT = Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
    "LABEL = LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('text', TEXT),('labels',LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_translate(sequence,lab, PROB = 1):\n",
    "    languages = ['en', 'fr', 'th', 'tr', 'ur', 'ru', 'bg', 'de', 'ar', 'zh-cn', 'hi',\n",
    "                 'sw', 'vi', 'es', 'el']\n",
    "    \n",
    "    #instantiate translator\n",
    "    translator = Translator()\n",
    "    \n",
    "    #store original language so we can convert back\n",
    "    org_lang = translator.detect(sequence).lang\n",
    "    \n",
    "    #randomly choose language to translate sequence to  \n",
    "    random_lang = np.random.choice([lang for lang in languages if lang is not org_lang])\n",
    "    #print(random_lang)\n",
    "    if org_lang in languages:\n",
    "        #translate to new language and back to original\n",
    "        translated = translator.translate(sequence, dest = random_lang).text\n",
    "        #translate back to original language\n",
    "        translated_back = translator.translate(translated, dest = org_lang).text\n",
    "        #print(translated,translated_back)\n",
    "        #apply with certain probability\n",
    "        if np.random.uniform(0, 1) <= PROB:\n",
    "            output_sequence = translated_back\n",
    "        else:\n",
    "            output_sequence = sequence\n",
    "            \n",
    "    #if detected language not in our list of languages, do nothing\n",
    "    else:\n",
    "        output_sequence = sequence\n",
    "    \n",
    "    return output_sequence,lab\n",
    "\n",
    "\n",
    "def random_deletion(words,lab, p=0.5): \n",
    "    if len(words) == 1: # return if single word\n",
    "        return words\n",
    "    remaining = list(filter(lambda x: random.uniform(0,1) > p,words)) \n",
    "    \n",
    "    if len(remaining) == 0: # if not left, sample a random word\n",
    "        return [random.choice(words)] ,lab\n",
    "    else:\n",
    "        return remaining,lab\n",
    "\n",
    "def random_swap(sentence,lab, n=5): \n",
    "    length = range(len(sentence)) \n",
    "    for _ in range(n):\n",
    "        idx1, idx2 = random.sample(length, 2)\n",
    "        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1] \n",
    "    return sentence,lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_pick(train_data):\n",
    "    num = np.random.randint(0,len(train_data.examples))\n",
    "    return train_data.examples[num].text,train_data.examples[num].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [Example.fromlist([df.iloc[i].sentence,df.iloc[i].label], fields) for i in range(df.shape[0])] \n",
    "\n",
    "CustomDataset = data.Dataset(example, fields)\n",
    "\n",
    "(train_data, valid_data) = CustomDataset.split(split_ratio=[0.85, 0.15], random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pbar = tqdm(range(0,1000))\n",
    "count = len(train_data.examples)\n",
    "print (f'Before the shape was :{len(train_data.examples)}' )\n",
    "\n",
    "aug_data = []\n",
    "aug_label = []\n",
    "for i in pbar:\n",
    "    \n",
    "    word,val = random_pick(train_data)\n",
    "    word_l = ' '.join(i for i in word)\n",
    "    word1,val1 = back_translate(word_l,val)\n",
    "    word1 = word1.split(' ')\n",
    "    \n",
    "    aug_data.append(word1)\n",
    "    aug_label.append(val1)\n",
    "\n",
    "    word,val = random_pick(train_data)\n",
    "    word2,val2 = random_deletion(word,val)\n",
    "    \n",
    "    aug_data.append(word2)\n",
    "    aug_label.append(val2)\n",
    "    \n",
    "    word,val = random_pick(train_data)\n",
    "    word3,val3 = random_swap(word,val)\n",
    "    \n",
    "    aug_data.append(word3)\n",
    "    aug_label.append(val3)\n",
    "    \n",
    "#     ins = {'sentence':[word1,word2,word3],'label':[val,val,val]}\n",
    "#     df2 = pd.concat([df2,pd.DataFrame(ins)])\n",
    "    \n",
    "pbar.set_description(desc = f'Loop:{i}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Class2'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.examples[0].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9593"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ray',\n",
       " 'Liotta',\n",
       " 'and',\n",
       " 'Jason',\n",
       " 'Patric',\n",
       " 'do',\n",
       " 'some',\n",
       " 'of',\n",
       " 'their',\n",
       " 'best',\n",
       " 'work',\n",
       " 'in',\n",
       " 'their',\n",
       " 'underwritten',\n",
       " 'roles',\n",
       " ',',\n",
       " 'but',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'be',\n",
       " 'fooled',\n",
       " ':',\n",
       " 'Nobody',\n",
       " 'deserves',\n",
       " 'any',\n",
       " 'prizes',\n",
       " 'here',\n",
       " '.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Class2'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.examples[0].text\n",
    "train_data.examples[0].labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "count = 9593\n",
    "for d,l in zip(aug_data,aug_label):\n",
    "#     train_data.examples[count].text = d\n",
    "#     train_data.examples[count]. = l\n",
    "    break\n",
    "    count+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-ZPPwSyXM9B"
   },
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Class2'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.examples[0].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "WyL3o2uUXM9B",
    "outputId": "8ccff20a-d5bc-44ce-b337-3931bbf595a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Very much a home video , and so devoid of artifice and purpose that it appears not to have been edited at all . '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Class1'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = ''\n",
    "filenumber = np.random.randint(1000)\n",
    "\n",
    "for i in train_data.examples[filenumber].text:\n",
    "    line += i + ' '\n",
    "line\n",
    "\n",
    "train_data.examples[filenumber].labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mg-qMQ6VtKCG"
   },
   "source": [
    "###  Build vocabulary for source and target from training data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': <torchtext.legacy.data.field.Field at 0x7fd0770008b0>,\n",
       " 'labels': <torchtext.legacy.data.field.LabelField at 0x7fd077000910>}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "q9PE4q54XM9B"
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bHVCk9oXM9C",
    "outputId": "bd0b0aea-a180-4e6c-ffbf-217698c93cba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input vocab :  17994\n",
      "Size of label vocab :  5\n",
      "Top 10 words appreared repeatedly : [('.', 9029), (',', 7943), ('the', 6812), ('of', 4948), ('and', 4899), ('a', 4895), ('to', 3392), ('-', 3138), ('is', 2809), (\"'s\", 2805)]\n",
      "Labels :  defaultdict(None, {'Class2': 0, 'Class4': 1, 'Class3': 2, 'Class5': 3, 'Class1': 4})\n"
     ]
    }
   ],
   "source": [
    "print('Size of input vocab : ', len(TEXT.vocab))\n",
    "print('Size of label vocab : ', len(LABEL.vocab))\n",
    "print('Top 10 words appreared repeatedly :', list(TEXT.vocab.freqs.most_common(10)))\n",
    "print('Labels : ', LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " print (list(TEXT.vocab.freqs.most_common())[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class2    2971\n",
       "Class4    2966\n",
       "Class3    2144\n",
       "Class5    1773\n",
       "Class1    1432\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kcc5kk8BtKCH"
   },
   "source": [
    "### train and test iteartor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "bogX6jtDXM9C"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch=True, # necessary for packed_padded_sequence\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "with open('tokenizer.pkl', 'wb') as tokens: \n",
    "    pickle.dump(TEXT.vocab.stoi, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Da-tC_aXM9C"
   },
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "n1udFd0cXM9D"
   },
   "outputs": [],
   "source": [
    "# Model class\n",
    "import torch.nn.functional as F\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim,emb_dim, hidden_dim, n_layers, dropout):\n",
    "        # input_dim <--- vocabulary size\n",
    "        # output_dim <--- len ([positive, negative]) == 2 \n",
    "        # emb_dim <--- embedding dimension of embedding matrix\n",
    "\n",
    "        super(Model, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.encoder = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout,batch_first=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src,Len):\n",
    "        # shape: [source_len, batch_size]\n",
    "        embedded = self.dropout(self.embedding(src)) # shape: [src_len, batch_size, embed_dim]\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, Len.to('cpu'),batch_first=True)\n",
    "        output, (hidden, cell) = self.encoder(packed) \n",
    "        # output shape -> [batch, hidden_dim]\n",
    "        # hiddden shape -> [n_layers, batch, hidden_dim]\n",
    "        # cell shape -> [n_layers, batch, hidden_dim]\n",
    "        output = self.fc2(self.fc1(hidden))\n",
    "        output = F.softmax(output, dim=1)\n",
    "        return output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJ4gPZzAXM9D",
    "outputId": "84645ba0-4413-489a-ca7c-234b2be7d703"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jd/anaconda3/envs/eva/lib/python3.8/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "#initializing variables and hyper parameters\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.4\n",
    "\n",
    "# initializing our model\n",
    "model = Model(INPUT_DIM, OUTPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "cssKRzERXM9E"
   },
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "k9LTjlYCXM9E"
   },
   "outputs": [],
   "source": [
    "# loop and train our model\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "# defining learnig rate scheduler (optional)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for batch in train_iterator:\n",
    "    src,data_len = batch.text\n",
    "    src = src.to(device)\n",
    "    trg = batch.labels.to(device)\n",
    "    trg = trg.long()\n",
    "    break\n",
    "    \n",
    "optimizer.zero_grad()\n",
    "output = model(src,data_len)\n",
    "\n",
    "\n",
    "trg.shape\n",
    "output.shape\n",
    "\n",
    "output.argmax(-1)\n",
    "\n",
    "total_correct = torch.sum(torch.eq(output.argmax(1), trg))\n",
    "total_count=len(trg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCGBCrHTtKCK"
   },
   "source": [
    "### Model training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "VPPTpYnFXM9E"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(EPOCH,model, iterator, optimizer=optimizer, criterion=criterion, clip=1,):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "    pbar = tqdm(iterator)\n",
    "    for i, batch in enumerate(pbar):\n",
    "        src,data_len = batch.text\n",
    "        src = src.to(device)\n",
    "        trg = batch.labels.to(device)\n",
    "        trg = trg.long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src,data_len)\n",
    "        \n",
    "        total_correct += torch.sum(torch.eq(output.argmax(1), trg))\n",
    "        total_count+=len(trg)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward() \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_description(desc= f'Epoch {EPOCH} Train data Batch No : {i} Loss : {loss.item():.3f} Accuracy : {total_correct/total_count * 100 :.2f}% ' )\n",
    "    \n",
    "    train_accuracy.append(total_correct/total_count)\n",
    "    mean_loss = epoch_loss / len(iterator)\n",
    "    train_loss.append(mean_loss)\n",
    "    \n",
    "    scheduler.step(mean_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcNqZfvctKCL"
   },
   "source": [
    "### Model Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git config --global user.email \"you@example.com\"\n",
    "git config --global user.name \"Your Name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "_-bx851mXM9G"
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(EPOCH,model, iterator, criterion,typ_loader):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    pbar  = tqdm(iterator)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i,batch in enumerate(pbar):\n",
    "            src,data_len = batch.text\n",
    "            src = src.to(device)\n",
    "            trg = batch.labels.to(device)\n",
    "            trg = trg.long()\n",
    "            predictions = model(src,data_len)\n",
    "            \n",
    "            loss = criterion(predictions, trg)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "            if typ_loader == 'Valid data':\n",
    "                validation_loss.append(loss)\n",
    "                validation_accuracy.append(acc)\n",
    "            elif typ_loader == 'Test data':\n",
    "                test_loss.append(loss)\n",
    "                test_accuracy.append(acc)\n",
    "            pbar.set_description(desc= f'Epoch {EPOCH} {typ_loader} Batch No : {i} Loss : {loss.item():.3f} | Accuracy : {epoch_acc / len(iterator)* 100 :.2f}% ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_CsZoXR2_SG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "BQoU37TFXM9G"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds.argmax(1) == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUowPx2KXM9H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYJ2RintXM9H",
    "outputId": "d4da680b-6d3d-4e2e-e8a6-1f2718b4ed83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train data Batch No : 74 Loss : 1.610 Accuracy : 14.65% : 100%|██████████| 75/75 [00:18<00:00,  4.13it/s]\n",
      "Epoch 0 Valid data Batch No : 13 Loss : 1.614 | Accuracy : 23.12% : 100%|██████████| 14/14 [00:00<00:00, 29.58it/s]\n",
      "Epoch 1 Train data Batch No : 74 Loss : 1.605 Accuracy : 17.79% : 100%|██████████| 75/75 [00:18<00:00,  4.10it/s]\n",
      "Epoch 1 Valid data Batch No : 13 Loss : 1.609 | Accuracy : 22.79% : 100%|██████████| 14/14 [00:00<00:00, 31.90it/s]\n",
      "Epoch 2 Train data Batch No : 74 Loss : 1.607 Accuracy : 21.80% : 100%|██████████| 75/75 [00:35<00:00,  2.14it/s]\n",
      "Epoch 2 Valid data Batch No : 13 Loss : 1.581 | Accuracy : 26.67% : 100%|██████████| 14/14 [00:00<00:00, 28.22it/s]\n",
      "Epoch 3 Train data Batch No : 74 Loss : 1.611 Accuracy : 26.04% : 100%|██████████| 75/75 [00:22<00:00,  3.38it/s]\n",
      "Epoch 3 Valid data Batch No : 13 Loss : 1.601 | Accuracy : 26.78% : 100%|██████████| 14/14 [00:00<00:00, 28.90it/s]\n",
      "Epoch 4 Train data Batch No : 74 Loss : 1.610 Accuracy : 24.57% : 100%|██████████| 75/75 [00:31<00:00,  2.36it/s]\n",
      "Epoch 4 Valid data Batch No : 13 Loss : 1.609 | Accuracy : 25.90% : 100%|██████████| 14/14 [00:00<00:00, 28.37it/s]\n",
      "Epoch 5 Train data Batch No : 74 Loss : 1.609 Accuracy : 15.19% : 100%|██████████| 75/75 [00:48<00:00,  1.54it/s]\n",
      "Epoch 5 Valid data Batch No : 13 Loss : 1.624 | Accuracy : 27.16% : 100%|██████████| 14/14 [00:00<00:00, 29.43it/s]\n",
      "Epoch 6 Train data Batch No : 74 Loss : 1.609 Accuracy : 18.26% : 100%|██████████| 75/75 [00:53<00:00,  1.40it/s]\n",
      "Epoch 6 Valid data Batch No : 7 Loss : 1.610 | Accuracy : 15.74% :  43%|████▎     | 6/14 [00:00<00:00, 47.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Valid data Batch No : 13 Loss : 1.609 | Accuracy : 27.03% : 100%|██████████| 14/14 [00:00<00:00, 32.64it/s]\n",
      "Epoch 7 Train data Batch No : 74 Loss : 1.609 Accuracy : 21.92% : 100%|██████████| 75/75 [00:41<00:00,  1.80it/s]\n",
      "Epoch 7 Valid data Batch No : 13 Loss : 1.610 | Accuracy : 26.67% : 100%|██████████| 14/14 [00:00<00:00, 30.07it/s]\n",
      "Epoch 8 Train data Batch No : 74 Loss : 1.611 Accuracy : 21.51% : 100%|██████████| 75/75 [00:43<00:00,  1.74it/s]\n",
      "Epoch 8 Valid data Batch No : 13 Loss : 1.615 | Accuracy : 26.39% : 100%|██████████| 14/14 [00:00<00:00, 30.06it/s]\n",
      "Epoch 9 Train data Batch No : 74 Loss : 1.610 Accuracy : 21.67% : 100%|██████████| 75/75 [00:43<00:00,  1.71it/s]\n",
      "Epoch 9 Valid data Batch No : 13 Loss : 1.651 | Accuracy : 26.72% : 100%|██████████| 14/14 [00:00<00:00, 30.85it/s]\n",
      "Epoch 10 Train data Batch No : 74 Loss : 1.611 Accuracy : 21.69% : 100%|██████████| 75/75 [00:42<00:00,  1.78it/s]\n",
      "Epoch 10 Valid data Batch No : 13 Loss : 1.639 | Accuracy : 26.91% : 100%|██████████| 14/14 [00:00<00:00, 29.84it/s]\n",
      "Epoch 11 Train data Batch No : 10 Loss : 1.611 Accuracy : 19.34% :  15%|█▍        | 11/75 [00:09<00:57,  1.11it/s]"
     ]
    }
   ],
   "source": [
    "total_epoch = 100\n",
    "for epoch in range(total_epoch):\n",
    "    result = train(epoch,model=model, iterator=train_iterator)\n",
    "    evaluate(epoch,model,valid_iterator,criterion,'Valid data')\n",
    "#     evaluate(epoch,model,test_iterator,criterion,'Test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xz-HGi6JXM9I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2uj_PfgXM9I"
   },
   "outputs": [],
   "source": [
    "predict('Very good') # predict funciton will predict if this is positive or negative review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stM8TNV9toH1"
   },
   "source": [
    "# predict('i recommend to watch the movie once. It is mindblowing') # predict funciton will predict if this is positive or negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "cXRPWnCguOh4",
    "outputId": "b63eea99-5878-4ed5-9277-765ea0a101b4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_accuracy,'green')\n",
    "plt.title('train_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "H_TH1AIWuQiS",
    "outputId": "674e82cd-7c3b-4e4f-942f-b8adf420e629"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_loss,'green')\n",
    "plt.title('train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "vDtwiMBYuTEY",
    "outputId": "26807711-5768-4351-f6ad-265446a648c3"
   },
   "outputs": [],
   "source": [
    "plt.plot(test_accuracy,'red')\n",
    "plt.title('test_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "oLBVuaF3uVjC",
    "outputId": "15368df8-eb33-4feb-e2f5-8336079e4b42"
   },
   "outputs": [],
   "source": [
    "plt.plot(test_loss,'red')\n",
    "plt.title('test_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "8g-0SHwBuX0Z",
    "outputId": "4ca55475-3aa1-40f3-82c1-4c8418c9b91b"
   },
   "outputs": [],
   "source": [
    "plt.plot(validation_accuracy,'blue')\n",
    "plt.title('test_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "KxmEnqAxuZ2R",
    "outputId": "b893bbe3-0b5b-443a-8549-01e7ab7319e0"
   },
   "outputs": [],
   "source": [
    "plt.plot(validation_loss,'blue')\n",
    "plt.title('test_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTIcFxMguc76"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "LSTM_sentiment_analysis_try.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
