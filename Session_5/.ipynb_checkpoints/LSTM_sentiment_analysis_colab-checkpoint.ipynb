{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3AIljihtKB5"
   },
   "source": [
    "### Importing Important Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NrSurWA_XM84"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "5848330f-e52f-49a7-ac18-ab07b0cb8136",
    "_uuid": "dc83c491-711e-4278-b0cc-24896e3e812f",
    "id": "K1cspYuNXM87"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy.datasets import IMDB\n",
    "from torchtext.legacy.data import Field, LabelField, BucketIterator,Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j6L6NAg5XM88"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch, torchtext\n",
    "import os\n",
    "import googletrans\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOhuk1CWtKB-"
   },
   "source": [
    "### Version chcek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "8YJ1c4vQXM88",
    "outputId": "65cb0501-2956-498c-bb8a-59cdbd263a5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Torch CUDA Version :10.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Torch Version :1.8.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Python Version :3.8.10 (default, May 19 2021, 18:05:58) \\n[GCC 7.3.0]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Torch CUDA Version :{torch.version.cuda}'\n",
    "f'Torch Version :{torch.__version__}'\n",
    "f'Python Version :{sys.version}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHAxLOfntKB_"
   },
   "source": [
    "### GPU Checker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ixoEQjp8XM89"
   },
   "outputs": [],
   "source": [
    "def gpu_check(seed_val = 1):\n",
    "    print('The Seed is set to {}'.format(seed_val))\n",
    "    if torch.cuda.is_available():\n",
    "        print('Model will Run on CUDA.')\n",
    "        print (\"Type 'watch nvidia-smi' to monitor GPU\\n\")\n",
    "        torch.cuda.manual_seed(seed_val)\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        torch.manual_seed(seed_val)\n",
    "        print ('Running in CPU')\n",
    "        device = 'cpu'\n",
    "    cuda = torch.cuda.is_available()\n",
    "    return cuda,seed_val,device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktIAtn89XM8-",
    "outputId": "5ae4969d-97e3-4adf-d393-cd39f570ac3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Seed is set to 1234\n",
      "Running in CPU\n"
     ]
    }
   ],
   "source": [
    "cuda,SEED,device = gpu_check(seed_val=1234)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZBmBSftXM8-",
    "outputId": "16cf6738-f23e-437b-ca6c-5abdf6130e0b"
   },
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_dataset(sst_dir):\n",
    "    sentiment_labels = pd.read_csv(os.path.join(sst_dir, \"sentiment_labels.txt\"), sep=\"|\")\n",
    "    sentence_ids = pd.read_csv(os.path.join(sst_dir, \"datasetSentences.txt\"), sep=\"\\t\")\n",
    "    dictionary = pd.read_csv(os.path.join(sst_dir, \"dictionary.txt\"), sep=\"|\", names=['phrase', 'phrase ids'])\n",
    "    train_test_split = pd.read_csv(os.path.join(sst_dir, \"datasetSplit.txt\"))\n",
    "    sentence_phrase_merge = pd.merge(sentence_ids, dictionary, left_on='sentence', right_on='phrase')\n",
    "    sentence_phrase_split = pd.merge(sentence_phrase_merge, train_test_split, on='sentence_index')\n",
    "    return pd.merge(sentence_phrase_split, sentiment_labels, on='phrase ids').sample(frac=1)\n",
    "\n",
    "def discretize_label(label):\n",
    "    if label <= 0.2: return 'Class1'\n",
    "    if label <= 0.4: return 'Class2'\n",
    "    if label <= 0.6: return 'Class3'\n",
    "    if label <= 0.8: return 'Class4'\n",
    "    return 'Class5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_dir = 'stanfordSentimentTreebank/'\n",
    "df = get_merged_dataset(sst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>phrase</th>\n",
       "      <th>phrase ids</th>\n",
       "      <th>splitset_label</th>\n",
       "      <th>sentiment values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>2351</td>\n",
       "      <td>Muccino seems to be exploring the idea of why ...</td>\n",
       "      <td>Muccino seems to be exploring the idea of why ...</td>\n",
       "      <td>67693</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>7892</td>\n",
       "      <td>Is the time really ripe for a warmed-over Jame...</td>\n",
       "      <td>Is the time really ripe for a warmed-over Jame...</td>\n",
       "      <td>146377</td>\n",
       "      <td>3</td>\n",
       "      <td>0.37500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081</th>\n",
       "      <td>3219</td>\n",
       "      <td>Based on Dave Barry 's popular book of the sam...</td>\n",
       "      <td>Based on Dave Barry 's popular book of the sam...</td>\n",
       "      <td>64257</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530</th>\n",
       "      <td>6830</td>\n",
       "      <td>If you 're looking to rekindle the magic of th...</td>\n",
       "      <td>If you 're looking to rekindle the magic of th...</td>\n",
       "      <td>146230</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>4823</td>\n",
       "      <td>If Signs is a good film , and it is , the esse...</td>\n",
       "      <td>If Signs is a good film , and it is , the esse...</td>\n",
       "      <td>106575</td>\n",
       "      <td>1</td>\n",
       "      <td>0.51389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_index                                           sentence  \\\n",
       "2257            2351  Muccino seems to be exploring the idea of why ...   \n",
       "7536            7892  Is the time really ripe for a warmed-over Jame...   \n",
       "3081            3219  Based on Dave Barry 's popular book of the sam...   \n",
       "6530            6830  If you 're looking to rekindle the magic of th...   \n",
       "4611            4823  If Signs is a good film , and it is , the esse...   \n",
       "\n",
       "                                                 phrase  phrase ids  \\\n",
       "2257  Muccino seems to be exploring the idea of why ...       67693   \n",
       "7536  Is the time really ripe for a warmed-over Jame...      146377   \n",
       "3081  Based on Dave Barry 's popular book of the sam...       64257   \n",
       "6530  If you 're looking to rekindle the magic of th...      146230   \n",
       "4611  If Signs is a good film , and it is , the esse...      106575   \n",
       "\n",
       "      splitset_label  sentiment values  \n",
       "2257               1           0.61111  \n",
       "7536               3           0.37500  \n",
       "3081               1           0.73611  \n",
       "6530               1           0.26389  \n",
       "4611               1           0.51389  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['sentiment values'].apply(discretize_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11286, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Class2    2971\n",
       "Class4    2966\n",
       "Class3    2144\n",
       "Class5    1773\n",
       "Class1    1432\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df[['sentence','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11286, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df2.to_csv('augmented_data.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df2 = pd.read_csv('augmented_data.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.concat([df,df2]).reset_index(drop =True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'... begins with promise , but runs aground after being snared in its own tangled plot .'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Class2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentence[2733]\n",
    "df.label[2733]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muccino seems to be exploring the idea of why ...</td>\n",
       "      <td>Class4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is the time really ripe for a warmed-over Jame...</td>\n",
       "      <td>Class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on Dave Barry 's popular book of the sam...</td>\n",
       "      <td>Class4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you 're looking to rekindle the magic of th...</td>\n",
       "      <td>Class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If Signs is a good film , and it is , the esse...</td>\n",
       "      <td>Class3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence   label\n",
       "0  Muccino seems to be exploring the idea of why ...  Class4\n",
       "1  Is the time really ripe for a warmed-over Jame...  Class2\n",
       "2  Based on Dave Barry 's popular book of the sam...  Class4\n",
       "3  If you 're looking to rekindle the magic of th...  Class2\n",
       "4  If Signs is a good film , and it is , the esse...  Class3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muccino seems to be exploring the idea of why ...</td>\n",
       "      <td>Class4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is the time really ripe for a warmed-over Jame...</td>\n",
       "      <td>Class2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence   label\n",
       "0  Muccino seems to be exploring the idea of why ...  Class4\n",
       "1  Is the time really ripe for a warmed-over Jame...  Class2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jd/anaconda3/envs/eva/lib/python3.8/site-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
     ]
    }
   ],
   "source": [
    "TEXT = Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
    "LABEL = LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('text', TEXT),('labels',LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_translate(sequence,lab, PROB = 1):\n",
    "    languages = ['en', 'fr', 'th', 'tr', 'ur', 'ru', 'bg', 'de', 'ar', 'zh-cn', 'hi',\n",
    "                 'sw', 'vi', 'es', 'el']\n",
    "    \n",
    "    #instantiate translator\n",
    "    translator = Translator()\n",
    "    \n",
    "    #store original language so we can convert back\n",
    "    org_lang = translator.detect(sequence).lang\n",
    "    \n",
    "    #randomly choose language to translate sequence to  \n",
    "    random_lang = np.random.choice([lang for lang in languages if lang is not org_lang])\n",
    "    #print(random_lang)\n",
    "    if org_lang in languages:\n",
    "        #translate to new language and back to original\n",
    "        translated = translator.translate(sequence, dest = random_lang).text\n",
    "        #translate back to original language\n",
    "        translated_back = translator.translate(translated, dest = org_lang).text\n",
    "        #print(translated,translated_back)\n",
    "        #apply with certain probability\n",
    "        if np.random.uniform(0, 1) <= PROB:\n",
    "            output_sequence = translated_back\n",
    "        else:\n",
    "            output_sequence = sequence\n",
    "            \n",
    "    #if detected language not in our list of languages, do nothing\n",
    "    else:\n",
    "        output_sequence = sequence\n",
    "    \n",
    "    return output_sequence,lab\n",
    "\n",
    "\n",
    "def random_deletion(words,lab, p=0.5): \n",
    "    if len(words) == 1: # return if single word\n",
    "        return words\n",
    "    remaining = list(filter(lambda x: random.uniform(0,1) > p,words)) \n",
    "    \n",
    "    if len(remaining) == 0: # if not left, sample a random word\n",
    "        return [random.choice(words)] ,lab\n",
    "    else:\n",
    "        return remaining,lab\n",
    "\n",
    "def random_swap(sentence,lab, n=5): \n",
    "    length = range(len(sentence)) \n",
    "    for _ in range(n):\n",
    "        idx1, idx2 = random.sample(length, 2)\n",
    "        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1] \n",
    "    return sentence,lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_pick(train_data):\n",
    "    num = np.random.randint(0,len(train_data.examples))\n",
    "    return train_data.examples[num].text,train_data.examples[num].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [Example.fromlist([df.iloc[i].sentence,df.iloc[i].label], fields) for i in range(df.shape[0])] \n",
    "\n",
    "CustomDataset = data.Dataset(example, fields)\n",
    "\n",
    "(train_data, valid_data) = CustomDataset.split(split_ratio=[0.85, 0.15], random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before the shape was :9593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [42:07<00:00,  2.53s/it]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(range(0,1000))\n",
    "count = len(train_data.examples)\n",
    "print (f'Before the shape was :{len(train_data.examples)}' )\n",
    "\n",
    "aug_data = []\n",
    "aug_label = []\n",
    "for i in pbar:\n",
    "    \n",
    "    word,val = random_pick(train_data)\n",
    "    word_l = ' '.join(i for i in word)\n",
    "    word1,val1 = back_translate(word_l,val)\n",
    "    word1 = word1.split(' ')\n",
    "    \n",
    "    aug_data.append(word1)\n",
    "    aug_label.append(val1)\n",
    "\n",
    "    word,val = random_pick(train_data)\n",
    "    word2,val2 = random_deletion(word,val)\n",
    "    \n",
    "    aug_data.append(word2)\n",
    "    aug_label.append(val2)\n",
    "    \n",
    "    word,val = random_pick(train_data)\n",
    "    word3,val3 = random_swap(word,val)\n",
    "    \n",
    "    aug_data.append(word3)\n",
    "    aug_label.append(val3)\n",
    "    \n",
    "#     ins = {'sentence':[word1,word2,word3],'label':[val,val,val]}\n",
    "#     df2 = pd.concat([df2,pd.DataFrame(ins)])\n",
    "    \n",
    "pbar.set_description(desc = f'Loop:{i}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Class2'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.examples[0].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9593"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    " train_data.examples.extend({'text':d,'labels':l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9595"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Since',\n",
       " 'Dahmer',\n",
       " 'resorts',\n",
       " 'to',\n",
       " 'standard',\n",
       " 'slasher',\n",
       " 'flick',\n",
       " 'thrills',\n",
       " 'when',\n",
       " 'it',\n",
       " 'should',\n",
       " 'be',\n",
       " 'most',\n",
       " 'in',\n",
       " 'the',\n",
       " 'mind',\n",
       " 'of',\n",
       " 'the',\n",
       " 'killer',\n",
       " ',',\n",
       " 'it',\n",
       " 'misses',\n",
       " 'a',\n",
       " 'major',\n",
       " 'opportunity',\n",
       " 'to',\n",
       " 'be',\n",
       " 'truly',\n",
       " 'revelatory',\n",
       " 'about',\n",
       " 'his',\n",
       " 'psyche',\n",
       " '.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.examples[9592].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['`',\n",
       " 'In',\n",
       " 'this',\n",
       " 'poor',\n",
       " 'remake',\n",
       " 'of',\n",
       " 'such',\n",
       " 'a',\n",
       " 'well',\n",
       " 'loved',\n",
       " 'classic',\n",
       " ',',\n",
       " 'Parker',\n",
       " 'exposes',\n",
       " 'the',\n",
       " 'limitations',\n",
       " 'of',\n",
       " 'his',\n",
       " 'skill',\n",
       " 'and',\n",
       " 'the',\n",
       " 'basic',\n",
       " 'flaws',\n",
       " 'in',\n",
       " 'his',\n",
       " 'vision',\n",
       " '.',\n",
       " \"'\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Class1'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 9593\n",
    "for d,l in zip(aug_data,aug_label):\n",
    "#     train_data.examples[count].text = d\n",
    "#     train_data.examples[count]. = l\n",
    "    break\n",
    "    count+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data.examples[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(train_data.examples[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-ZPPwSyXM9B"
   },
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.examples[0].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "WyL3o2uUXM9B",
    "outputId": "8ccff20a-d5bc-44ce-b337-3931bbf595a6"
   },
   "outputs": [],
   "source": [
    "line = ''\n",
    "filenumber = np.random.randint(1000)\n",
    "\n",
    "for i in train_data.examples[filenumber].text:\n",
    "    line += i + ' '\n",
    "line\n",
    "\n",
    "train_data.examples[filenumber].labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mg-qMQ6VtKCG"
   },
   "source": [
    "###  Build vocabulary for source and target from training data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9PE4q54XM9B"
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bHVCk9oXM9C",
    "outputId": "bd0b0aea-a180-4e6c-ffbf-217698c93cba"
   },
   "outputs": [],
   "source": [
    "print('Size of input vocab : ', len(TEXT.vocab))\n",
    "print('Size of label vocab : ', len(LABEL.vocab))\n",
    "print('Top 10 words appreared repeatedly :', list(TEXT.vocab.freqs.most_common(10)))\n",
    "print('Labels : ', LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " print (list(TEXT.vocab.freqs.most_common())[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kcc5kk8BtKCH"
   },
   "source": [
    "### train and test iteartor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bogX6jtDXM9C"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch=True, # necessary for packed_padded_sequence\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "with open('tokenizer.pkl', 'wb') as tokens: \n",
    "    pickle.dump(TEXT.vocab.stoi, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Da-tC_aXM9C"
   },
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n1udFd0cXM9D"
   },
   "outputs": [],
   "source": [
    "# Model class\n",
    "import torch.nn.functional as F\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim,emb_dim, hidden_dim, n_layers, dropout):\n",
    "        # input_dim <--- vocabulary size\n",
    "        # output_dim <--- len ([positive, negative]) == 2 \n",
    "        # emb_dim <--- embedding dimension of embedding matrix\n",
    "\n",
    "        super(Model, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.encoder = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout,batch_first=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src,Len):\n",
    "        # shape: [source_len, batch_size]\n",
    "        embedded = self.dropout(self.embedding(src)) # shape: [src_len, batch_size, embed_dim]\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, Len.to('cpu'),batch_first=True)\n",
    "        output, (hidden, cell) = self.encoder(packed) \n",
    "        # output shape -> [batch, hidden_dim]\n",
    "        # hiddden shape -> [n_layers, batch, hidden_dim]\n",
    "        # cell shape -> [n_layers, batch, hidden_dim]\n",
    "        output = self.fc2(self.fc1(hidden))\n",
    "        output = F.softmax(output, dim=1)\n",
    "        return output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJ4gPZzAXM9D",
    "outputId": "84645ba0-4413-489a-ca7c-234b2be7d703"
   },
   "outputs": [],
   "source": [
    "#initializing variables and hyper parameters\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.4\n",
    "\n",
    "# initializing our model\n",
    "model = Model(INPUT_DIM, OUTPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cssKRzERXM9E"
   },
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9LTjlYCXM9E"
   },
   "outputs": [],
   "source": [
    "# loop and train our model\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "# defining learnig rate scheduler (optional)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for batch in train_iterator:\n",
    "    src,data_len = batch.text\n",
    "    src = src.to(device)\n",
    "    trg = batch.labels.to(device)\n",
    "    trg = trg.long()\n",
    "    break\n",
    "    \n",
    "optimizer.zero_grad()\n",
    "output = model(src,data_len)\n",
    "\n",
    "\n",
    "trg.shape\n",
    "output.shape\n",
    "\n",
    "output.argmax(-1)\n",
    "\n",
    "total_correct = torch.sum(torch.eq(output.argmax(1), trg))\n",
    "total_count=len(trg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCGBCrHTtKCK"
   },
   "source": [
    "### Model training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPPTpYnFXM9E"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(EPOCH,model, iterator, optimizer=optimizer, criterion=criterion, clip=1,):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "    pbar = tqdm(iterator)\n",
    "    for i, batch in enumerate(pbar):\n",
    "        src,data_len = batch.text\n",
    "        src = src.to(device)\n",
    "        trg = batch.labels.to(device)\n",
    "        trg = trg.long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src,data_len)\n",
    "        \n",
    "        total_correct += torch.sum(torch.eq(output.argmax(1), trg))\n",
    "        total_count+=len(trg)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward() \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_description(desc= f'Epoch {EPOCH} Train data Batch No : {i} Loss : {loss.item():.3f} Accuracy : {total_correct/total_count * 100 :.2f}% ' )\n",
    "    \n",
    "    train_accuracy.append(total_correct/total_count)\n",
    "    mean_loss = epoch_loss / len(iterator)\n",
    "    train_loss.append(mean_loss)\n",
    "    \n",
    "    scheduler.step(mean_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcNqZfvctKCL"
   },
   "source": [
    "### Model Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-bx851mXM9G"
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(EPOCH,model, iterator, criterion,typ_loader):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    pbar  = tqdm(iterator)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i,batch in enumerate(pbar):\n",
    "            src,data_len = batch.text\n",
    "            src = src.to(device)\n",
    "            trg = batch.labels.to(device)\n",
    "            trg = trg.long()\n",
    "            predictions = model(src,data_len)\n",
    "            \n",
    "            loss = criterion(predictions, trg)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "            if typ_loader == 'Valid data':\n",
    "                validation_loss.append(loss)\n",
    "                validation_accuracy.append(acc)\n",
    "            elif typ_loader == 'Test data':\n",
    "                test_loss.append(loss)\n",
    "                test_accuracy.append(acc)\n",
    "            pbar.set_description(desc= f'Epoch {EPOCH} {typ_loader} Batch No : {i} Loss : {loss.item():.3f} | Accuracy : {epoch_acc / len(iterator)* 100 :.2f}% ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_CsZoXR2_SG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQoU37TFXM9G"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds.argmax(1) == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUowPx2KXM9H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYJ2RintXM9H",
    "outputId": "d4da680b-6d3d-4e2e-e8a6-1f2718b4ed83"
   },
   "outputs": [],
   "source": [
    "total_epoch = 100\n",
    "for epoch in range(total_epoch):\n",
    "    result = train(epoch,model=model, iterator=train_iterator)\n",
    "    evaluate(epoch,model,valid_iterator,criterion,'Valid data')\n",
    "#     evaluate(epoch,model,test_iterator,criterion,'Test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xz-HGi6JXM9I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2uj_PfgXM9I"
   },
   "outputs": [],
   "source": [
    "predict('Very good') # predict funciton will predict if this is positive or negative review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stM8TNV9toH1"
   },
   "source": [
    "# predict('i recommend to watch the movie once. It is mindblowing') # predict funciton will predict if this is positive or negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "cXRPWnCguOh4",
    "outputId": "b63eea99-5878-4ed5-9277-765ea0a101b4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_accuracy,'green')\n",
    "plt.title('train_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "H_TH1AIWuQiS",
    "outputId": "674e82cd-7c3b-4e4f-942f-b8adf420e629"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_loss,'green')\n",
    "plt.title('train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "vDtwiMBYuTEY",
    "outputId": "26807711-5768-4351-f6ad-265446a648c3"
   },
   "outputs": [],
   "source": [
    "plt.plot(test_accuracy,'red')\n",
    "plt.title('test_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "oLBVuaF3uVjC",
    "outputId": "15368df8-eb33-4feb-e2f5-8336079e4b42"
   },
   "outputs": [],
   "source": [
    "plt.plot(test_loss,'red')\n",
    "plt.title('test_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "8g-0SHwBuX0Z",
    "outputId": "4ca55475-3aa1-40f3-82c1-4c8418c9b91b"
   },
   "outputs": [],
   "source": [
    "plt.plot(validation_accuracy,'blue')\n",
    "plt.title('test_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "KxmEnqAxuZ2R",
    "outputId": "b893bbe3-0b5b-443a-8549-01e7ab7319e0"
   },
   "outputs": [],
   "source": [
    "plt.plot(validation_loss,'blue')\n",
    "plt.title('test_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTIcFxMguc76"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "LSTM_sentiment_analysis_try.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
